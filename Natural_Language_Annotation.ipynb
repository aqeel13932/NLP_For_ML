{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Natural Language Annotation for Machine Learning By James Pustejovsky, Amber Stubbs\n",
    "To Get The Book : \n",
    "\n",
    "http://shop.oreilly.com/product/0636920020578.do\n",
    "\n",
    "https://www.amazon.com/Natural-Language-Annotation-Machine-Learning/dp/1449306667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 1 The Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice: in the following example he put the word in center so we know the context of the word in many cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 69 matches:\n",
      "usic ] [ music stops ] HEAD KNIGHT OF NI : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni !\n",
      "] [ music stops ] HEAD KNIGHT OF NI : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni !\n",
      "] HEAD KNIGHT OF NI : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ARTHUR : W\n",
      "D KNIGHT OF NI : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ARTHUR : Who ar\n",
      "GHT OF NI : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ARTHUR : Who are you\n",
      "F NI : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ARTHUR : Who are you ? HE\n",
      ": Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ARTHUR : Who are you ? HEAD KN\n",
      "! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ARTHUR : Who are you ? HEAD KNIGHT \n",
      "HT : We are the Knights Who Say ... ' Ni '! RANDOM : Ni ! ARTHUR : No ! Not th\n",
      " Knights Who Say ... ' Ni '! RANDOM : Ni ! ARTHUR : No ! Not the Knights Who S\n",
      "THUR : No ! Not the Knights Who Say ' Ni '! HEAD KNIGHT : The same ! BEDEVERE \n",
      "are the keepers of the sacred words : Ni , Peng , and Neee - wom ! RANDOM : Ne\n",
      "! HEAD KNIGHT : The Knights Who Say ' Ni ' demand a sacrifice ! ARTHUR : Knigh\n",
      "and a sacrifice ! ARTHUR : Knights of Ni , we are but simple travellers who se\n",
      "es beyond these woods . HEAD KNIGHT : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni !\n",
      "woods . HEAD KNIGHT : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ... ARTHUR\n",
      " . HEAD KNIGHT : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ... ARTHUR : Ow\n",
      "AD KNIGHT : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ... ARTHUR : Ow ! Ow\n",
      "IGHT : Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ... ARTHUR : Ow ! Ow ! Ow\n",
      ": Ni ! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ... ARTHUR : Ow ! Ow ! Ow ! Ag\n",
      "! KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! Ni ! ... ARTHUR : Ow ! Ow ! Ow ! Agh ! H\n",
      " ! Agh ! HEAD KNIGHT : We shall say ' ni ' again to you if you do not appease \n",
      " chord ] ARTHUR : A what ? KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! ARTHUR and PART\n",
      "d ] ARTHUR : A what ? KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! ARTHUR and PARTY : O\n",
      "RTHUR : A what ? KNIGHTS OF NI : Ni ! Ni ! Ni ! Ni ! ARTHUR and PARTY : Ow ! O\n"
     ]
    }
   ],
   "source": [
    "text6.concordance(\"Ni\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Complete example how to use your own text with NLTK and generate concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 48 matches:\n",
      " , why do so many children ' s films treat their target audience with utter con\n",
      "or all it ' s worth : the characters treat their situation as if it were dead s\n",
      "und music for halloween trick - or - treat parties . all - in - all , a wonderf\n",
      "der and mature teenagers , i . e . , treat the movie as it were rated nc - 17 .\n",
      "ame time . and the finale ' s a real treat as well . . . chan delivers yet anot\n",
      "k like a mob boss is truly a special treat . the caveman ' s valentine starring\n",
      "or all it ' s worth : the characters treat their situation as if it were dead s\n",
      " i went to mcdonald ' s yesterday to treat myself to a mcflurry , and tarzan wa\n",
      "ose . nazis and slave traders : both treat groups of others as less than human \n",
      "he characters as they are or as they treat others . the three hour running is p\n",
      "l of their part . however , the real treat is jessica campbell in her confused \n",
      "th that actor ' s face is invited to treat themselves to a product from one of \n",
      "oldsmith also is a plus . mulan is a treat , more powerful than hercules , with\n",
      "e must - see for sci - fi fans and a treat for anyone who enjoys decently acted\n",
      "ich side one person is on . the real treat , of course , is pam grier who gives\n",
      "a while . ) and before you know it , treat williams , wes studi and famke janse\n",
      "iar faces . so far so good . our man treat is the hero , he ' ll live . wes is \n",
      ", and seeing them together is a real treat . they both do a great job at smooth\n",
      "ms ) , a psych professor , agrees to treat him , and the two begin a rocky rela\n",
      " jessica brooks and josh paddock . a treat for some movie goers is to see werne\n",
      "ome life with his parents are also a treat . gavin ' s over - protective mother\n",
      " to make things work again . spencer treat clark , as the dunne ' s young son j\n",
      "his laziness , but they don ' t just treat him as fodder for cheap shots either\n",
      "ly a fan of action movies , but is a treat for those viewers who often like to \n",
      " doors and asks for a \" funky little treat . \" the solid , sexy cast smooths ou\n"
     ]
    }
   ],
   "source": [
    "corpus_loc = 'training/'\n",
    "docs = nltk.corpus.PlaintextCorpusReader(corpus_loc,'.*\\.txt')\n",
    "# make sure that file has been read\n",
    "#print docs.fileids()\n",
    "docs_processd = nltk.Text(docs.words())\n",
    "docs_processd.concordance(\"treat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### You can download google dataset for ngram 1->5 by this <a href='https://books.google.com/ngrams/'>link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK Tagger \n",
    "* ( Tag <i>part of speech <b>POS</b></i>)\n",
    "* Tags give each word a tag like \n",
    "    * FW-> Foreign Word.\n",
    "    * DT-> Determiner\n",
    "    * VBZ-> Verb , 3rd person singular present\n",
    "    * NN-> Noun, Singular or mass\n",
    "* Check tagset for Brown ,LOB, London-Lund Corpus, Penn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('test', 'NN'), ('.', '.')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "pos_tag(word_tokenize(\"This is a test.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### examples which doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Clean', 'JJ'), ('dishes', 'NNS'), ('are', 'VBP'), ('in', 'IN'), ('the', 'DT'), ('cabinet', 'NN'), ('.', '.')]\n",
      "[('Clean', 'JJ'), ('dishes', 'NNS'), ('before', 'IN'), ('going', 'VBG'), ('to', 'TO'), ('work', 'VB'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "print pos_tag(word_tokenize(\"Clean dishes are in the cabinet.\"))\n",
    "print pos_tag(word_tokenize(\"Clean dishes before going to work!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Defining Your Goal and Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### split your goal from data to two things : \n",
    "* write statement of purpose that covers the very basics of your task.\n",
    "* use that sentence to expand on \"how\"s of your goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib import urlopen\n",
    "url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
    "raw = urlopen(url).read()\n",
    "#print raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "To remove HTML markup, use BeautifulSoup's get_text() function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-280437d42e64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://www.bbc.co.uk/news/world-us-canada-18963939\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/aqeel/anaconda2/envs/fullfeatured/lib/python2.7/site-packages/nltk/util.pyc\u001b[0m in \u001b[0;36mclean_html\u001b[1;34m(html)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"To remove HTML markup, use BeautifulSoup's get_text() function\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: To remove HTML markup, use BeautifulSoup's get_text() function"
     ]
    }
   ],
   "source": [
    "from urllib import urlopen\n",
    "import nltk\n",
    "url = \"http://www.bbc.co.uk/news/world-us-canada-18963939\"\n",
    "html= urlopen(url).read()\n",
    "raw = nltk.clean_html(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Corpus Analytics\n",
    "* different dataset used ( couldn't find the original one).\n",
    "* types : are the words them selfs for example: \"the\",\"of\" so on.\n",
    "* rank: after ordering the types by frequency the highst frequency given rank one and so on.\n",
    "* frequency spectrum : the number of types that have specific fequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "imdbcorpus = PlaintextCorpusReader('./training','.*')\n",
    "from nltk import FreqDist\n",
    "fd1 = FreqDist(imdbcorpus.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832564 832564\n",
      "30417\n",
      "11432\n",
      "[u'woods', u'spiders', u'hanging', u'woody', u'comically', u'localized', u'scold', u'originality', u'mutinies', u'rickman', u'slothful', u'wracked', u'capoeira', u'rawhide', u'bringing', u'liaisons', u'grueling', u'sommerset', u'wooden', u'wednesday', u'crotch', u'elgar', u'stereotypical', u'shows', u'sooty', u'inevitably', u'francesco', u'feasibility', u'bannister', u'mortgages', u'gorman', u'francesca', u'scraped', u'inanimate', u'errors', u'tiered', u'cooking', u'fonzie', u'videodrome', u'designing', u'succumb', u'shocks', u'crooned', u'ching', u'china', u'shandling', u'wiseguy', u'natured', u'existentialist', u'kids']\n"
     ]
    }
   ],
   "source": [
    "print fd1.N() , len(imdbcorpus.words()) # total number of sample outcomes (number of words)\n",
    "print fd1.B() # total number of sample values that have counts greater than zero\n",
    "print len(fd1.hapaxes()) #number of samples that occured only once.\n",
    "fequentwords = fd1.keys()\n",
    "print fequentwords[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pmi (pointwise mutual information) how much one word tells us about the other.\n",
    "* pmi(x;y) = ln (P(x,y)/P(x)*P(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'\\x05\\x05', u'euuugh'),\n",
       " (u'165', u'mph'),\n",
       " (u'289', u'460'),\n",
       " (u'460', u'939'),\n",
       " (u'750', u'batting'),\n",
       " (u'84', u'carat'),\n",
       " (u'^', u'os'),\n",
       " (u'_angel', u'heart_'),\n",
       " (u'_animal', u'house_'),\n",
       " (u'_boogie', u'nights_')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder1 = nltk.BigramCollocationFinder.from_words(imdbcorpus.words())\n",
    "finder1.nbest(bigram_measures.pmi,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder1.apply_freq_filter(10) # look only at collection that occure 10 times or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'judi', u'dench'),\n",
       " (u'del', u'toro'),\n",
       " (u'gretchen', u'mol'),\n",
       " (u'nigel', u'hawthorne'),\n",
       " (u'ving', u'rhames'),\n",
       " (u'stellan', u'skarsgard'),\n",
       " (u'winona', u'ryder'),\n",
       " (u'christina', u'ricci'),\n",
       " (u'san', u'francisco'),\n",
       " (u'ned', u'devine')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder1.nbest(bigram_measures.pmi,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'dalai', u'lama'),\n",
       " (u'ashley', u'judd'),\n",
       " (u'uma', u'thurman'),\n",
       " (u'los', u'angeles'),\n",
       " (u'raging', u'bull'),\n",
       " (u'natalie', u'portman'),\n",
       " (u'keanu', u'reeves'),\n",
       " (u'denise', u'richards'),\n",
       " (u'liam', u'neeson'),\n",
       " (u'ewan', u'mcgregor')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder1.apply_freq_filter(15)\n",
    "finder1.nbest(bigram_measures.pmi,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check page 64 , 65 if you want to know more about P(w_i|w_1^{i-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 4 Building Your Model and Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=http://www.resourcebook.eu/searchll.php#> Data base of NLP resources maintained by the European language resources Association <b>ELRA</b></a>\n",
    "also take a look at the xml file ( DTD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 : Applying and Adopting Annotation Standards\n",
    "how we can annotate a text for different usages.\n",
    "<b>most important ones that made sense</b>\n",
    "* Stand-off Annotation by Character Location. (depend on start end position + label).\n",
    "     * multiple annotations could be applied on the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 6 : Annotation and Adjudication\n",
    "* in this link you can get annotators to annotate your text for cheap prices : https://www.mturk.com/mturk/welcome\n",
    "* Link to download reviews for movies http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "### Questions : \n",
    "many questions should be answered : \n",
    "* how many tags , or max length , specifiy when tag is applied and when not , provide examples. \n",
    "* many types exist : like tag per word , tag per string length , or multiple tags.\n",
    "* Check page 127-128 to under stand <b>Cohen's Kappa</b> $$K = \\frac{Pr(a)-Pr(e)}{1-Pr(e)}$$\n",
    "\n",
    "<b>Pr(a)</b>: total cases where both annotators agreed / total cases .\n",
    "\n",
    "<b>Pr(e)</b>: expected agreement between annotators if each annotator was to randomly pick a category for each annotation.\n",
    "Pr(e) : we calculate the precentage for each annotator on each category then we multiply the precentage from both annotators for the same category and so on for all categories after that we sum all these values.\n",
    "<b>Fleiss's Kappa (K)</b> (for more than two annotators)\n",
    "$$FK = \\frac{P-P_e}{1-P_e}$$ \n",
    "$$P = \\frac{P_i}{n}$$\n",
    "$$P_i = \\frac{\\sum_{c=1}^{k}a_{ic}^2}{a(a-1)}$$ \n",
    "$$P_e = sum(P_c^2)$$ \n",
    "$$P_c = \\frac{1}{Aa}\\sum_{i=1}^{A}a_{ic}$$\n",
    "<b>c</b> stand for category of classification.\n",
    "\n",
    "<b>A</b> number of reviews.(number of samples).\n",
    "\n",
    "<b>a</b> number of annotation per review (how many annotators annotate this sample)\n",
    "\n",
    "(more info pages 128,129,130,131)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7, Training: Machine Learning.\n",
    "* More details for NLP ML : check these books \n",
    "    * Natural Language Processing with Python by Steven Bird .. O'Reilly, 2009\n",
    "    * Foundation of Statistical Natural language Processing by Chris Manning .. (MIT Press , 1999)\n",
    "    * Speech and Language Processing by Daniel Jurafsky.. ( Prentice Hall, 2008) \n",
    "    * Machine learning by Tom Mitchel (McGraw-Hill , 1997)\n",
    "* Types of features for NLP (in this book): \n",
    "    * <b>N-gram features</b>: bag of words , each word treated as feature. using statistics allow using larger window like bigram , n-gram depending on windows size\n",
    "    * <b>Structure-dependent feature (SD features)</b>: virtue of the properties of the data structure itself. for example if we are speaking about words our features might be first letter , last letter, prefix, suffex , word length. if senetence it might be first word last word sentence length so on.\n",
    "    * <b> Annotation-depedent features (AD features)</b>: includes any features that are associated with an annotation specification that reflects a model of the data for example : lebels marking the thpe of an entity as Person, Organization or Place within an NE \"Names Entitiy\"\n",
    "\n",
    "* Things to dig more : \n",
    "    * Sequence Induction Algorithms.\n",
    "    * Transductive learning\n",
    "    * Inductive learning\n",
    "* Table at Pages (165-166) good to know what algorithm suite what type of NLP case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 8 : Testing and Evaluation\n",
    "* talking about some metrics like precision, recall, F-measure etc...\n",
    "* other metrics like : T-test , Analysis of variance (ANOVA) , X-squared (chi-squared) , Receiver Operator Characteristic (ROC) curves.\n",
    "* some famous problems ( small data set , over fitting , splet data to train -dev etc.. ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9 : Revising and Reporting\n",
    "* information about how to report your resutls, what to include what to execlude and how to revise your work wither the revise should be done in any level of your progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Annotation : TimeML\n",
    "* speaks about TimeML project <a href=\"http://timeml.org\">http://timeml.org</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Automatic Annotation: Generating TimeML\n",
    "* in general speaks about how TimeML were broken to small problems for easier machine annotating. (so the machine can annotate the text instead of human).\n",
    "* rule-based got the best results in some tasks for annotating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: Afterword: The Future of Annotation\n",
    "* speaks abount ways to annotate data (amazon mturk, Games with a purpos (GWAP) , user generated content.\n",
    "* speaks also about big data , boosting , active learning , semi-supervised learning, distributing systems and shared langauge applications (LAPPS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A:\n",
    "* some important corpora for future:\n",
    "    * <a href=\"http://vlm1.uta.edu/~athitsos/asl_lexicon\">American Sign Language</a>\n",
    "    * <a href=\"http://privatewww.essex.ac.uk/~melhaj/easc.htm\"> Essex Arabic Summaries Corpus</a> (Link didn't work)\n",
    "    * <a href=\"http://spandh.dcs.shef.ac.uk/gridcorpus/\">GRID</a> link video with audio and text (1000 sentence, 34 speaker).\n",
    "    * <a href=\"http://www.euromatrixplus.net/multi-un/\">UN Parallel text 2000-2010 (arabic included)</a>\n",
    "    * <a href=\"http://www-i6.informatik.rwth-aachen.de/aslr/\">German Sign Language</a>\n",
    "    * <a href=\"http://uudb.speech-lab.org/\">Japaense speech</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [fullfeatured]",
   "language": "python",
   "name": "Python [fullfeatured]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
